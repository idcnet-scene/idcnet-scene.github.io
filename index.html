<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="IDC-Net jointly generates RGB-D videos with explicit camera control using a geometry-aware diffusion model and transformer block, improving visual and geometric consistency, enabling direct use for 3D scene reconstruction without extra processing.">
  <meta name="keywords" content="IDCNet, RGBD, video generation, camera control, diffusion model, geometry-aware transformer">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>IDCNet</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="https://img.icons8.com/poly/90/potted-plant.png">
  <!-- <img width="90" height="90" src="https://img.icons8.com/poly/90/potted-plant.png" alt="potted-plant"/> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h3 class="title is-1 publication-title">IDCNet: Guided Video Diffusion for Metric-Consistent RGBD Scene Generation
            with Precise Camera Control</h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Lijuan Liu</a>,</span>
              <!-- <a href="">Anonymous</a> -->
              <!-- <span class="author-block"> -->
              <!-- <a href="https://utkarshsinha.com">Utkarsh Sinha</a><sup>2</sup>,</span> -->
            <span class="author-block">
              <a href="">Wenfa Li</a>,
            </span>
            <span class="author-block"> 
              <a href="">Dongbo Zhang</a>,
            </span>
            <span class="author-block">
              <a href="">Shuo Wang</a>,
            </span>
            <span class="author-block">
              <a href="">Shaohui Jiao</a><sup>&dagger;</sup>
            </span>
            <!-- <span class="author-block"> -->
              <!-- <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup> -->
            <!-- </span> -->
          </div>

          <br>
            <div class="is-size-5 publication-authors">
              <!-- <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> Sea AI Lab</span> -->
              <span class="author-block">Bytedance Inc.</span>
              <span class="author-block" STYLE="font-size:12.0pt">&nbsp&nbsp<sup>&dagger;</sup>Corresponding Author</span>
              <br>
            </div>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington,</span>
            <span class="author-block"><sup>2</sup>Google Research</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link.
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> --> 
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths"> 
        <!-- <div class="column is-full"> -->
          <img id="teaser" width="125%" style="max-width: 125%;display: block; margin: 0 auto; transform: translateX(-10%);" src="./static/scene_poster_1.png">
          <p>
            We present IDC-Net, a novel framework that, given metric-aligned RGB-D inputs and camera trajectories, generates
RGB-D sequences with precise camera control. Thanks to the metric alignment between generated depths and camera poses,
the outputs enable direct 3D reconstruction without post-processing.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>





<section class="section" style="background-color:#efeff081">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          We present IDC-Net (Image-Depth Consistency Network),
a novel framework designed to generate RGB-D video sequences
under explicit camera trajectory control. Unlike approaches
that treat RGB and depth generation separately,
IDC-Net jointly synthesizes both RGB images and corresponding
depth maps within a unified geometry-aware diffusion
model. The joint learning framework strengthens spatial
and geometric alignment across frames, enabling more
precise camera control in the generated sequences. To support
the training of this camera-conditioned model and ensure
high geometric fidelity, we construct a camera-imagedepth
consistent dataset with metric-aligned RGB videos,
depth maps, and accurate camera poses, which provides
precise geometric supervision with notably improved interframe
geometric consistency. Moreover, we introduce a
geometry-aware transformer block that enables fine-grained
camera control, enhancing control over the generated sequences.
Extensive experiments show that IDC-Net achieves
improvements over state-of-the-art approaches in both visual
quality and geometric consistency of generated scene
sequences. Notably, the generated RGB-D sequences can be
directly feed for downstream 3D Scene reconstruction tasks
without extra post-processing steps, showcasing the practical
benefits of our joint learning framework.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-3">Video Results with Given Trajectory</h3>
        <div class="publication-video" style="display: flex; flex-direction: column; align-items: center; gap: 20px;">
          <!-- <video id="dollyzoom" autoplay controls muted loop playsinline width="150%">
            <source src="../more_videos/group_0_new.mp4"
                    type="video/mp4">
          </video> -->

          <!-- <video id="dollyzoom" autoplay controls muted loop playsinline width="150%">
            <source src="../cam_cntrl_videos/cameras_002_new.mp4"
                    type="video/mp4">
          </video> -->

          <!-- <video id="dollyzoom" autoplay controls muted loop playsinline width="150%">
            <source src="../cam_cntrl_videos/cameras1_0q.mp4"
                    type="video/mp4">
          </video> -->
        <!-- </div>
      </div>
    </div> --> 
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- <div class="columns is-centered"> -->

      <!-- Visual Effects. -->
      <div class="column is-full-width">
        <div class="content">
          <h2 class="title is-3">Video Results with Given Trajectory</h2>
          <p>
            IDCNet generates RGB-D scenes from input RGB-D data and given trajectories. Each row shows videos generated from different prompts under a shared trajectory.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 125%; max-width: 125%;display: block; margin: 0 auto; transform: translateX(-10%);">
            <source src="./cam_cntrl_videos/cameras_002_new.mp4"
                    type="video/mp4">
          </video>
          <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 125%; max-width: 125%;display: block; margin: 0 auto; transform: translateX(-10%);">
            <source src="./cam_cntrl_videos/cameras1_014_new.mp4"
                    type="video/mp4">
          </video>
          <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 125%; max-width: 125%;display: block; margin: 0 auto; transform: translateX(-10%);">
            <source src="./cam_cntrl_videos/cameras1_033_new.mp4"
                    type="video/mp4">
          </video>
          
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">More Video Results</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Additional RGB-D results generated by IDCNet from varying input prompts and trajectories.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 125%; max-width: 125%;display: block; margin: 0 auto; transform: translateX(-10%);">
              <source src="./more_videos/group_0_new.mp4"
                      type="video/mp4">
            </video>
            <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 125%; max-width: 125%;display: block; margin: 0 auto; transform: translateX(-10%);">
              <source src="./more_videos/group_3_new.mp4"
                      type="video/mp4">
            </video>
            <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 125%; max-width: 125%;display: block; margin: 0 auto; transform: translateX(-10%);">
              <source src="./more_videos/group_1_new.mp4"
                      type="video/mp4">
            </video>
            <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 125%; max-width: 125%;display: block; margin: 0 auto; transform: translateX(-10%);">
              <source src="./more_videos/group_2_new.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      <!-- </div> -->
    </div>
    <!--/ Matting. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="../more_videos/group_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="../more_videos/group_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="../more_videos/group_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="../more_videos/group_0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div> -->
      <!-- </div>
    </div>
  </div>
</section> --> -->

<section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> The Method </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              <!-- BuboGPT connects different modality Q-Former with pre-trained large language model <a href="https://github.com/lm-sys/FastChat">Vicuna</a>, using a simple projection matrix.   We consider a two-stage instruction-tuning procedure:
          <ul type="1">
            <li><b>Stage 1:  Single-modal Pre-training</b>. <span style="font-size: 95%;">We train the corresponding modality Q-Former and linear projection layer on a large number of modality-text paired
data.</span></li>
            <li><b>Stage 2:  Multi-Modal Instruct Tuning</b>. <span style="font-size: 95%;">We curate a high-quality multi-modal instruction-following
dataset to fine tune only the linear projection layer:
              <ul type="1">
                <li> <b>Image-Text</b>: We employ two previously published datasets from <a href="https://minigpt-4.github.io/">MiniGPT-4</a> and <a href="https://llava-vl.github.io/">LLaVa</a> for visual instruct tuning.</li>
                <li> <b>Audio-Text</b>: We build a series of expressive and descriptive data to facilitate this process based on <a href="https://arxiv.org/abs/1910.09387">Clotho</a> dataset.</span></li>
                <li> <b>Audio-Image-Text</b>: We build &lt;audio, image, text&gt; pairs to act as triple-modality instruction tuning dataset based on <a href="https://arxiv.org/abs/2104.02691">VGGSS</a> dataset
                  and further introduce negative set to enhance our model.</span></li>
              </ul>  
          </ul>  -->
              <!--          Please check out ``LLaVA-13b-delta-v0'' model checkpoint on -->
              <!--          <a href="https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0">[HuggingFace Models]</a>.-->
              As the figure shown, IDC-Net jointly generates RGB and depth sequences in latent space, conditioned
on an input frame and target camera trajectory. Camera poses are embedded through a GeoAware transformer to enforce
spatial consistency. The generated metrically aligned RGB-D outputs enable direct point cloud extraction, supporting immediate
downstream 3D reconstruction
            </p>
          </div>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" width="80%" src="./static/framework.png">
              <figcaption>
                The framework of IDC-Net.
              </figcaption>
            </div>

            <!--      -->
            <!--      </centering>           -->
        </div>
      </div>


  </section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{
      <!-- park2021nerfies, -->
  <!-- author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo}, -->
  <!-- title     = {Nerfies: Deformable Neural Radiance Fields}, -->
  <!-- journal   = {ICCV}, -->
  <!-- year      = {2021}, -->
}</code></pre>
  </div>
</section> -->


<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>
